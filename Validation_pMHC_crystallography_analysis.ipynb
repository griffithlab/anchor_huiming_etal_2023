{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mdtraj\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.stats as ss\n",
    "import random\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "all_anchor_overall_pos_score_dict = load_obj('all_anchor_overall_pos_score_dict_r4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_split(table):\n",
    "    dict_by_chain = {}\n",
    "    resSeq_tracker = {}\n",
    "    serial_Name = {}\n",
    "    count = 0\n",
    "    for n,i in table.iterrows():\n",
    "        count += 1\n",
    "        if i['chainID'] not in serial_Name:\n",
    "            serial_Name[i['chainID']] = {}\n",
    "        if i['resSeq'] not in serial_Name[i['chainID']]:\n",
    "            serial_Name[i['chainID']][i['resSeq']] = []\n",
    "        try:\n",
    "            if i['resSeq'] in resSeq_tracker[i['chainID']]:\n",
    "                serial_Name[i['chainID']][i['resSeq']].append(n)\n",
    "                continue\n",
    "            else:\n",
    "                dict_by_chain[i['chainID']].append(i['resName'])\n",
    "                resSeq_tracker[i['chainID']].append(i['resSeq'])\n",
    "                serial_Name[i['chainID']][i['resSeq']].append(n)\n",
    "        except:\n",
    "            dict_by_chain[i['chainID']] = [i['resName']]\n",
    "            resSeq_tracker[i['chainID']] = [i['resSeq']]\n",
    "            serial_Name[i['chainID']][i['resSeq']] = [n]\n",
    "    return dict_by_chain, resSeq_tracker, serial_Name\n",
    "\n",
    "def calculate_distance(HLA, peptide, traj, criteria='avg'):\n",
    "    group_list = []\n",
    "    for i in peptide.keys():\n",
    "        for j in peptide[i]:\n",
    "            for k in list(itertools.chain.from_iterable(list(HLA.values()))):\n",
    "                group_list.append([j,k])\n",
    "    distances = mdtraj.compute_distances(traj, group_list)\n",
    "    init_dict = {j:[] for i in peptide.keys() for j in peptide[i]}\n",
    "    return_dict = {i:{j:0} for i in peptide.keys() for j in peptide[i]}\n",
    "    for i,j in enumerate(group_list):\n",
    "        init_dict[j[0]].append(distances[0][i])\n",
    "    if criteria == 'min':\n",
    "        for i in return_dict.keys():\n",
    "            for j in peptide[i]:\n",
    "                one_res_data = init_dict[j]\n",
    "                return_dict[i][j] = np.min(one_res_data)\n",
    "    elif criteria == 'avg':\n",
    "        for i in return_dict.keys():\n",
    "            for j in peptide[i]:\n",
    "                one_res_data = init_dict[j]\n",
    "                return_dict[i][j] = np.mean(one_res_data)\n",
    "    elif criteria == 'max':\n",
    "        for i in return_dict.keys():\n",
    "            for j in peptide[i]:\n",
    "                one_res_data = init_dict[j]\n",
    "                return_dict[i][j] = np.max(one_res_data)\n",
    "        \n",
    "    return init_dict, return_dict\n",
    "\n",
    "def calculate_SASA(n_peptide, traj):\n",
    "    residue_sizes = [traj.topology.chain(i).n_residues for i in range(0,traj.n_chains)]\n",
    "    agg_res_sizes = [sum(residue_sizes[:i]) for i in range(0,traj.n_chains+1)]\n",
    "    peptide_ind = [i for i in range(agg_res_sizes[n_peptide],agg_res_sizes[n_peptide+1])]\n",
    "    sasa = mdtraj.shrake_rupley(traj, mode='residue')\n",
    "    peptide_sasa = [sasa[0,i] for i in peptide_ind]\n",
    "    return peptide_sasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize dictionaries\n",
    "SASA_results = {}\n",
    "Distance_with_percentile_results = {}\n",
    "sample_hla_query = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through each entry (strucutre: sample_id, peptide_seq, peptide_length)\n",
    "with open('cleaned_list_pdb_structures.tsv', 'r') as file:\n",
    "    for line in file:\n",
    "        entry = line.strip('\\n')\n",
    "        hla_details, sample, peptide, peptide_length = entry.split(\"\\t\")   \n",
    "        print(sample, peptide, peptide_length)\n",
    "        if \"HLA-\"+hla_details not in sample_hla_query:\n",
    "            sample_hla_query[\"HLA-\"+hla_details] = [(sample,peptide,peptide_length)]\n",
    "        else:\n",
    "            sample_hla_query[\"HLA-\"+hla_details].append((sample,peptide,peptide_length))\n",
    "        \n",
    "        if sample in SASA_results or sample in Distance_with_percentile_results:\n",
    "            print(\"Already calculated for sample: \"+sample)\n",
    "        else:\n",
    "            file_name = \"pdb_files/\"+sample+\".pdb\"\n",
    "            hla = mdtraj.load(file_name)\n",
    "            hla_name = \"HLA-\"+hla_details\n",
    "            table, bonds = hla.topology.to_dataframe()\n",
    "            dict_by_chain, resSeq_tracker, serial = chain_split(table)\n",
    "            n_hla = 0\n",
    "            n_peptide = 2\n",
    "            for i in dict_by_chain.keys():\n",
    "                if (i == 0 and len(dict_by_chain[i]) > 290) or (i == 0 and len(dict_by_chain[i]) < 269):\n",
    "                    print(file_name, i, len(dict_by_chain[i]), \"ERROR\")\n",
    "                    print([(j, len(dict_by_chain[j])) for j in dict_by_chain.keys()])\n",
    "                    break\n",
    "                if (i == 2 and len(dict_by_chain[i]) != int(peptide_length)):\n",
    "                    for (chain_id, length) in [(j, len(dict_by_chain[j])) for j in dict_by_chain.keys()]:\n",
    "                        if int(length) == int(peptide_length):\n",
    "                            n_peptide = chain_id\n",
    "                            print('NEW n_peptide: ' + str(n_peptide))\n",
    "                            print('SAMPLE ERROR: ' +sample)\n",
    "                            break\n",
    "                \n",
    "            ## threshold for top x closest locations considered as metric (only applies to distance not SASA)\n",
    "            percentile = 50\n",
    "\n",
    "            ## DISTANCE CALCULATIONS\n",
    "            HLA_mol = serial[n_hla]\n",
    "            peptide_mol = serial[n_peptide]\n",
    "            ## For each atom in each residue, calculate minimum distance between it and any HLA atom \n",
    "            init, summary_min = calculate_distance(HLA_mol, peptide_mol, hla, criteria='min')\n",
    "\n",
    "            ## Determine which locations are backbone and which are not\n",
    "            not_backbone_ind = hla.top.select('not backbone')\n",
    "            backbone_ind = hla.top.select('backbone')\n",
    "\n",
    "            new_summary_min = {}\n",
    "            for i in summary_min.keys():\n",
    "                count = 0\n",
    "                new_summary_min[i] = {}\n",
    "                for j in summary_min[i]:\n",
    "                    if j in not_backbone_ind:\n",
    "                        count += 1\n",
    "                        new_summary_min[i][j] = summary_min[i][j]\n",
    "                if count == 0:\n",
    "                    new_summary_min[i] = summary_min[i]\n",
    "                    #print(\"This entry does not have non-backbone atom: \", i)\n",
    "\n",
    "            min_summary_perc = {i:0 for i in new_summary_min.keys()}\n",
    "            for i in new_summary_min:\n",
    "                entry = [new_summary_min[i][j] for j in new_summary_min[i]]\n",
    "                min_summary_perc[i] = np.mean(np.array([k for k in entry if k <= np.percentile(entry,percentile)]))\n",
    "\n",
    "            ## SASA CALCULATIONS\n",
    "            peptide_sasa = calculate_SASA(n_peptide, hla)\n",
    "\n",
    "            ## Add calculations to dataset\n",
    "            SASA_results[sample] = peptide_sasa\n",
    "            Distance_with_percentile_results[sample] = [min_summary_perc[i] for i in min_summary_perc.keys()]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SASA_results), len(Distance_with_percentile_results))\n",
    "print(Counter([len(SASA_results[i]) for i in SASA_results.keys()]))\n",
    "for i in Distance_with_percentile_results.keys():\n",
    "    if len(Distance_with_percentile_results[i]) > 11:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate file for input to pvacbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hla_name in sample_hla_query.keys():\n",
    "    all_peptides = {9:[], 8:[], 10:[], 11:[]}\n",
    "    for sample,peptide,peptide_length in sample_hla_query[hla_name]:\n",
    "        if int(peptide_length) > 11:\n",
    "            continue\n",
    "        else:\n",
    "            all_peptides[int(peptide_length)].append(peptide)\n",
    "    for length in [8,9,10,11]:\n",
    "        if len(all_peptides[length]) != 0:\n",
    "            with open(\"pvacbind_files/anchor_validation_pvacbind_\"+hla_name+\"-\"+str(length)+\".fa\", \"w+\") as fasta_file:\n",
    "                for i,j in enumerate(all_peptides[length]):\n",
    "                    fasta_file.write(\">\"+str(i+1)+'\\n')\n",
    "                    fasta_file.write(j+'\\n')\n",
    "                fasta_file.close()\n",
    "\n",
    "with open(\"pvacbind_files/anchor_validation_pvacbind_query.tsv\", \"w+\") as file:\n",
    "    file.write(\"HLA\"+\"\\t\"+\"length\"+'\\n')\n",
    "    for hla_name in sample_hla_query.keys():\n",
    "        all_peptides = {9:[], 8:[], 10:[], 11:[]}\n",
    "        for sample,peptide,peptide_length in sample_hla_query[hla_name]:\n",
    "            if int(peptide_length) > 11:\n",
    "                break\n",
    "            else:\n",
    "                all_peptides[int(peptide_length)].append(peptide)\n",
    "        for i in all_peptides.keys():\n",
    "            if len(all_peptides[i]) != 0:\n",
    "                file.write(hla_name+\"\\t\"+str(i)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with pvacbind results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_data = pd.read_csv(\"./validation_analysis_pvacbind_output_combined.txt\", delimiter='\\t')\n",
    "sample_data = pd.read_csv(\"pdb_files/cleaned_list_pdb_structures.tsv\", delimiter='\\t', header=None)\n",
    "sample_data_with_binding = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_with_binding['HLA Allele'] = sample_data[0]\n",
    "sample_data_with_binding['PDB_ID'] = sample_data[1]\n",
    "sample_data_with_binding['Peptide'] = sample_data[2]\n",
    "sample_data_with_binding['Length'] = sample_data[3]\n",
    "best_binding = []\n",
    "median_binding = []\n",
    "SASA_vs_Predicted = []\n",
    "SASA_vs_Predicted_pval = []\n",
    "Distance_vs_Predicted = []\n",
    "Distance_vs_Predicted_pval = []\n",
    "randomized_SASA = []\n",
    "randomized_Distance = []\n",
    "\n",
    "for n, i in sample_data_with_binding.iterrows():\n",
    "    matched_entry = binding_data.loc[(binding_data['Epitope Seq'] == i['Peptide']) & (binding_data['HLA Allele'] == \"HLA-\"+i['HLA Allele'])].iloc[0]\n",
    "    best_binding.append(matched_entry['Best Score'])\n",
    "    median_binding.append(matched_entry['Median Score'])\n",
    "    sasa_calculation = SASA_results[i['PDB_ID']]\n",
    "    distance_calculation = Distance_with_percentile_results[i['PDB_ID']]\n",
    "    prediction_calculation = all_anchor_overall_pos_score_dict[\"HLA-\"+i['HLA Allele']][len(i['Peptide'])]\n",
    "    corr1, p1 = ss.spearmanr(sasa_calculation, prediction_calculation)\n",
    "    corr2, p2 = ss.spearmanr(distance_calculation, prediction_calculation)\n",
    "    SASA_vs_Predicted.append(corr1)\n",
    "    SASA_vs_Predicted_pval.append(p1)\n",
    "    Distance_vs_Predicted.append(corr2)\n",
    "    Distance_vs_Predicted_pval.append(p2)\n",
    "    random.shuffle(sasa_calculation)\n",
    "    random.shuffle(distance_calculation)\n",
    "    ran_corr1, ran_p1 = ss.spearmanr(sasa_calculation, prediction_calculation)\n",
    "    ran_corr2, ran_p2 = ss.spearmanr(distance_calculation, prediction_calculation)\n",
    "    randomized_SASA.append(ran_corr1)\n",
    "    randomized_Distance.append(ran_corr2)\n",
    "\n",
    "\n",
    "sample_data_with_binding['Best_Score'] = best_binding\n",
    "sample_data_with_binding['Median_Score'] = median_binding\n",
    "sample_data_with_binding['Distance'] = Distance_vs_Predicted\n",
    "sample_data_with_binding['Distance_Pval'] = Distance_vs_Predicted_pval\n",
    "sample_data_with_binding['SASA'] = SASA_vs_Predicted\n",
    "sample_data_with_binding['SASA_Pval'] = SASA_vs_Predicted_pval\n",
    "sample_data_with_binding['Random SASA'] = randomized_SASA\n",
    "sample_data_with_binding['Random Distance'] = randomized_Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating Random Subset for plotting\n",
    "index_dictionary = {}\n",
    "for n, i in sample_data_with_binding.iterrows():\n",
    "    if i['HLA Allele'] in index_dictionary:\n",
    "        index_dictionary[i['HLA Allele']].append(n)\n",
    "    else:\n",
    "        index_dictionary[i['HLA Allele']] = [n]\n",
    "        \n",
    "random_subset = []\n",
    "for i in index_dictionary.keys():\n",
    "    data = index_dictionary[i]\n",
    "    if len(data) > 5:\n",
    "        random_data = random.sample(data, k=5)\n",
    "        random_subset += random_data\n",
    "    else:\n",
    "        random_subset += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metrics = [\"Best_Score\", \"Median_Score\"]\n",
    "correlation_metrics = [\"Distance\", \"SASA\"]\n",
    "sample_data_with_binding_subset = sample_data_with_binding.iloc[random_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_with_binding.to_csv(\"All_Data_with_Binding_and Correlation_Info.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_with_binding_subset.to_csv(\"Subset_Data_with_Binding_and Correlation_Info.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-test for sample distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss.ttest_ind(sample_data_with_binding_subset['Distance'], sample_data_with_binding_subset['Random Distance'], equal_var=False))\n",
    "print(ss.ttest_ind(sample_data_with_binding_subset['SASA'], sample_data_with_binding_subset['Random SASA'], equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_data_with_binding_subset[sample_data_with_binding_subset['Distance'] <= 0])/len(sample_data_with_binding_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Spearman Correlation Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Joint Plot\n",
    "fig, axes = plt.subplots(2,1, figsize=(12,15))\n",
    "\n",
    "sns.distplot(sample_data_with_binding_subset['Distance'], hist=False, rug=True, label=\"Distance Correlation\", ax=axes[0]);\n",
    "sns.distplot(sample_data_with_binding_subset['Random Distance'], hist=False, rug=True, label=\"Randomized Correlation\", ax=axes[0]);\n",
    "axes[0].set_xlabel('Spearman Correlation')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].title.set_text('Distribution of Spearman Correlations between Anchor Prediction & Distance Calculation')\n",
    "\n",
    "sns.distplot(sample_data_with_binding_subset['SASA'], hist=False, rug=True, label=\"SASA Correlation\", ax=axes[1]);\n",
    "sns.distplot(sample_data_with_binding_subset['Random SASA'], hist=False, rug=True, label=\"Randomized Correlation\", ax=axes[1]);\n",
    "axes[1].set_xlabel('Spearman Correlation')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].title.set_text('Distribution of Spearman Correlations between Anchor Prediction & SASA Calculation')\n",
    "plt.savefig('../../Anchor Paper/Main Figure 3/Distribution of Spearman Correlations between Anchor Prediction & Distance joint SASA Calculation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_allele = 'HLA-A*02:01'\n",
    "length = 9\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "fig.suptitle(\"Anchor Validation Data for \"+HLA_allele+\" at length \" + str(length), fontweight='bold', fontsize=13, x=0.55)\n",
    "for j in [i[0] for i in sample_hla_query[HLA_allele] if i[2] == str(length)]:\n",
    "    x_pos = [k for k in range(1,length+1)]\n",
    "    distance_result = Distance_with_percentile_results[j]\n",
    "    sasa_result = SASA_results[j]\n",
    "\n",
    "    axs[0].plot(x_pos, distance_result)\n",
    "    axs[0].set_title('Distances between atoms of peptide at each position to all possible atoms of HLA')\n",
    "    axs[0].set(ylabel='Distance (Å)')\n",
    "\n",
    "    axs[1].plot(x_pos, sasa_result)\n",
    "    axs[1].set_title('SASA of peptide at each position when in complex with HLA molecule')\n",
    "    axs[1].set(ylabel='SASA ($Å^2$)', xlabel='Positions')\n",
    "\n",
    "plt.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_allele = 'HLA-A*02:01'\n",
    "length = 9\n",
    "\n",
    "columns = [i for i in range(1,10)]\n",
    "dataset_0201_distance = []\n",
    "dataset_0201_sasa = []\n",
    "\n",
    "for j in [i[0] for i in sample_hla_query[HLA_allele] if i[2] == str(length)]:\n",
    "    #print(j)\n",
    "    x_pos = [k for k in range(1,length+1)]\n",
    "    distance_result = Distance_with_percentile_results[j]\n",
    "    dataset_0201_distance.append(distance_result)\n",
    "    sasa_result = SASA_results[j]\n",
    "    dataset_0201_sasa.append(sasa_result)\n",
    "dataset_0201_distance_df = pd.DataFrame(dataset_0201_distance, columns=columns)\n",
    "dataset_0201_sasa_df = pd.DataFrame(dataset_0201_sasa, columns=columns)\n",
    "dataset_0201_distance_df.to_csv(\"HLA-A*02:01_pMHC_crystallography_analysis_distance.tsv\", sep='\\t')\n",
    "dataset_0201_sasa_df.to_csv(\"HLA-A*02:01_pMHC_crystallography_analysis_sasa.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_allele = 'HLA-B*08:01'\n",
    "length = 9\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "fig.suptitle(\"Anchor Validation Data for \"+HLA_allele+\" at length \" + str(length), fontweight='bold', fontsize=13, x=0.55)\n",
    "for j in [i[0] for i in sample_hla_query[HLA_allele] if i[2] == str(length)]:\n",
    "    x_pos = [k for k in range(1,length+1)]\n",
    "    distance_result = Distance_with_percentile_results[j]\n",
    "    sasa_result = SASA_results[j]\n",
    "\n",
    "    axs[0].plot(x_pos, distance_result)\n",
    "    axs[0].set_title('Distances between atoms of peptide at each position to all possible atoms of HLA')\n",
    "    axs[0].set(ylabel='Distance (Å)')\n",
    "\n",
    "    axs[1].plot(x_pos, sasa_result)\n",
    "    axs[1].set_title('SASA of peptide at each position when in complex with HLA molecule')\n",
    "    axs[1].set(ylabel='SASA ($Å^2$)', xlabel='Positions')\n",
    "\n",
    "plt.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_allele = 'HLA-B*08:01'\n",
    "length = 9\n",
    "\n",
    "columns = [i for i in range(1,10)]\n",
    "dataset_0801_distance = []\n",
    "dataset_0801_sasa = []\n",
    "\n",
    "for j in [i[0] for i in sample_hla_query[HLA_allele] if i[2] == str(length)]:\n",
    "    x_pos = [k for k in range(1,length+1)]\n",
    "    distance_result = Distance_with_percentile_results[j]\n",
    "    dataset_0801_distance.append(distance_result)\n",
    "    sasa_result = SASA_results[j]\n",
    "    dataset_0801_sasa.append(sasa_result)\n",
    "dataset_0801_distance_df = pd.DataFrame(dataset_0801_distance, columns=columns)\n",
    "dataset_0801_sasa_df = pd.DataFrame(dataset_0801_sasa, columns=columns)\n",
    "dataset_0801_distance_df.to_csv(\"HLA-B*08:01_pMHC_crystallography_analysis_distance.tsv\", sep='\\t')\n",
    "dataset_0801_sasa_df.to_csv(\"HLA-B*08:01_pMHC_crystallography_analysis_sasa.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
