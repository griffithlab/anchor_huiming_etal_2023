{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02335b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import upsetplot\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pylab as pl\n",
    "import difflib\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "## Plotting the frequency of anchor positions for a certain length\n",
    "def anchor_pos_freq_by_length(filtered_anchor_dict, length):\n",
    "    pos = [i+1 for i in range(length)]\n",
    "    freq = [0 for i in range(length)]\n",
    "    for i in filtered_anchor_dict.keys():\n",
    "        try:\n",
    "            for j in filtered_anchor_dict[i][length]:\n",
    "                freq[j-1] += 1\n",
    "        except:\n",
    "            continue\n",
    "    plt.bar(pos, freq)\n",
    "    plt.xlabel(\"peptide positions\")\n",
    "    plt.ylabel(\"Frequency in dataset\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return freq\n",
    "\n",
    "### Method for determining anchor position\n",
    "### criteria:\n",
    "### determine contribution of each position to overall percentage\n",
    "### Set cutoff at X =?\n",
    "    \n",
    "def percentage_cutoff(normalized_list, cutoff):\n",
    "    count = 0\n",
    "    anchor_list = []\n",
    "    #print(normalized_list)\n",
    "    indexed_list = sorted([(i,j) for i,j in enumerate(normalized_list)],key=lambda x:(-x[1],x[0]))\n",
    "    #print(indexed_list)\n",
    "    for n,m in indexed_list:\n",
    "        if count > cutoff:\n",
    "            break\n",
    "        else:\n",
    "            count += m\n",
    "            anchor_list.append(n+1)\n",
    "    return anchor_list\n",
    "\n",
    "def anchor_pos_score_by_contribution(anchor_score_dict, percentage):\n",
    "    normalized_dict = {}\n",
    "    filter_contr = {}\n",
    "    for i in anchor_score_dict.keys():\n",
    "        normalized_dict[i] = {}\n",
    "        filter_contr[i] = {}\n",
    "        for j in anchor_score_dict[i].keys():\n",
    "            sum_val = sum(anchor_score_dict[i][j])\n",
    "            normalized_dict[i][j] = (anchor_score_dict[i][j])/sum_val\n",
    "            filter_contr[i][j] = percentage_cutoff(normalized_dict[i][j], percentage)\n",
    "\n",
    "    return normalized_dict, filter_contr\n",
    "\n",
    "def anchor_pos_score_by_contribution_with_base(anchor_score_dict, percentage):\n",
    "    normalized_dict = {}\n",
    "    filter_contr = {}\n",
    "    for i in anchor_score_dict.keys():\n",
    "        normalized_dict[i] = {}\n",
    "        filter_contr[i] = {}\n",
    "        for j in anchor_score_dict[i].keys():\n",
    "            base_score_dict = anchor_score_dict[i][j]-min(anchor_score_dict[i][j])\n",
    "            sum_val = sum(base_score_dict)\n",
    "            normalized_dict[i][j] = (base_score_dict)/sum_val\n",
    "            filter_contr[i][j] = percentage_cutoff(normalized_dict[i][j], percentage)\n",
    "\n",
    "    return normalized_dict, filter_contr\n",
    "\n",
    "### Shared counting functions\n",
    "def anchor_category_determine(condensed_info_row, cutoff):\n",
    "    if condensed_info_row['Median Fold Change'] > 1:\n",
    "        if condensed_info_row['Mutation at Anchor'] == 1:\n",
    "            if condensed_info_row['Median WT Score'] <= cutoff:\n",
    "                decision = 'Reject'\n",
    "                group = '3B'\n",
    "            else:\n",
    "                decision = 'Accept'\n",
    "                group = '2'\n",
    "        else:\n",
    "            decision = 'Accept'\n",
    "            group = '1A'\n",
    "    else:\n",
    "        if condensed_info_row['Mutation at Anchor'] == 1:\n",
    "            decision = 'Reject'\n",
    "            group = '3A'\n",
    "        else:\n",
    "            decision = 'Accept'\n",
    "            group = '1B'\n",
    "    return decision, group\n",
    "    \n",
    "def original_decision(condensed_info_row):\n",
    "    if condensed_info_row['Median Fold Change'] > 1 and condensed_info_row['Median MT Score']:\n",
    "        decision = 'Accept'\n",
    "    else:\n",
    "        decision = 'Reject'\n",
    "    return decision\n",
    "\n",
    "\n",
    "def naive_anchor_category_determine(condensed_info_row, cutoff):\n",
    "    if condensed_info_row['Median Fold Change'] > 1:\n",
    "        if condensed_info_row['Mutation Position'] in [2,condensed_info_row['Peptide Length']]:\n",
    "            if condensed_info_row['Median WT Score'] <= cutoff:\n",
    "                decision = 'Reject'\n",
    "                group = '3B'\n",
    "            else:\n",
    "                decision = 'Accept'\n",
    "                group = '2'\n",
    "        else:\n",
    "            decision = 'Accept'\n",
    "            group = '1A'\n",
    "    else:\n",
    "        if condensed_info_row['Mutation Position'] in [2,condensed_info_row['Peptide Length']]:\n",
    "            decision = 'Reject'\n",
    "            group = '3A'\n",
    "        else:\n",
    "            decision = 'Accept'\n",
    "            group = '1B'\n",
    "    return decision, group\n",
    "\n",
    "def count_set_occurrences(input_table, filter_list):\n",
    "    table = []\n",
    "    for index, filters in input_table.iterrows():\n",
    "        members = []\n",
    "        for j in filter_list:\n",
    "            decision = filters[j]\n",
    "            if decision == 'Accept':\n",
    "                members.append(j)\n",
    "        table.append(members)\n",
    "    set_table = set(map(tuple, table))\n",
    "    final_count = Counter(map(tuple, table))\n",
    "    output_table = []\n",
    "    counts = []\n",
    "    for i in set_table:\n",
    "        counts.append(final_count[i])\n",
    "        output_table.append(list(i))\n",
    "    return output_table, counts\n",
    "\n",
    "def difference_between_peptides(a,b):\n",
    "    diff_pos = []\n",
    "    if len(a) != len(b):\n",
    "        print(\"INPUT LENGTHS NOT EQUAL\")\n",
    "    for i, (j, k) in enumerate(zip(a,b)):\n",
    "        if j != k :\n",
    "            diff_pos.append(i+1)\n",
    "    return diff_pos\n",
    "\n",
    "def if_anchor_matches_mutation_pos(mutation_type, wt_peptide, mt_peptide, mutation_pos, HLA_allele, anchor_dict):\n",
    "    matched = False\n",
    "    length = len(mt_peptide)\n",
    "    anchor_list = anchor_dict[HLA_allele][length]\n",
    "    if mutation_type == \"missense\" or mutation_type == 'inframe_del': \n",
    "        if pd.isna(wt_peptide):\n",
    "            print('NULL WT Peptide')\n",
    "        else:\n",
    "            diff_pos = difference_between_peptides(wt_peptide, mt_peptide)\n",
    "            #print(\"Different Position: \", diff_pos, mutation_pos, wt_peptide, mt_peptide)\n",
    "            if set(diff_pos).issubset(anchor_list):\n",
    "                matched = True\n",
    "                #print(\"Matched Anchor: \", anchor_list)\n",
    "    elif mutation_type == 'FS' or mutation_type == 'inframe_ins': ### DOES THIS NEED CHANGING? inframe_ins should be followed by difference_between_peptides?\n",
    "        if mutation_pos != 0 or mutation_pos != -1:\n",
    "            diff_pos = list(range(mutation_pos, length+1))\n",
    "            if set(diff_pos).issubset(anchor_list):\n",
    "                matched = True\n",
    "                #print(\"FS/ins mutation matched to anchor: \", anchor_list) \n",
    "                #print(\"FS/ins mutation positions: \", diff_pos, length, anchor_list, HLA_allele)\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab184204",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cutoff at 80% contribution\n",
    "all_anchor_overall_pos_score_dict_r4 = load_obj('all_anchor_overall_pos_score_dict_r4')\n",
    "normalized_anchor_dict_r4, filtered_anchor_dict_r4 = anchor_pos_score_by_contribution(all_anchor_overall_pos_score_dict_r4, 0.8)\n",
    "anchor_pos_freq_by_length(filtered_anchor_dict_r4,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bde47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_1000_m2_filter_500b_1 = pd.read_csv('filter_500b_TCGA_1000_m1_pvacseq_analysis_combined.txt', sep='\\t')\n",
    "tcga_1000_m2_filter_500b_2 = pd.read_csv('filter_500b_TCGA_1000_m1_pvacseq_re_analysis_combined.txt', sep='\\t')\n",
    "tcga_1000_m2_filter_500b = tcga_1000_m2_filter_500b_1.append(tcga_1000_m2_filter_500b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bac21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_1000_m2_filter_100b = tcga_1000_m2_filter_500b[tcga_1000_m2_filter_500b[\"Median MT Score\"] < 100]\n",
    "tcga_1000_m2_filter_50b = tcga_1000_m2_filter_500b[tcga_1000_m2_filter_500b[\"Median MT Score\"] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(tcga_1000_m2_filter_500b[\"HLA Allele\"])), len(np.unique(tcga_1000_m2_filter_100b[\"HLA Allele\"])), len(np.unique(tcga_1000_m2_filter_50b[\"HLA Allele\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_impact_analysis(data, anchor_dict, cutoff):\n",
    "    hla_anchor_data = pd.DataFrame()\n",
    "\n",
    "    hla_alleles_for_r4 = np.sort(data['HLA Allele'])\n",
    "    print(\"Number of HLA alleles included in samples from method 1: \", len(np.unique(hla_alleles_for_r4)))\n",
    "\n",
    "    ### For each entry, determine if mutation is at anchor position\n",
    "    condensed_info = []\n",
    "    for n, i in data.iterrows():\n",
    "        if pd.isna(i['Mutation Position']):\n",
    "            print('mutation position is NA', n)\n",
    "            continue\n",
    "        mut_pos = int(i['Mutation Position'])\n",
    "        wt_seq = i['WT Epitope Seq']\n",
    "        mt_seq = i['MT Epitope Seq']\n",
    "        wt_binding = i['Median WT Score']\n",
    "        mt_binding = i['Median MT Score']\n",
    "        hla_allele = i['HLA Allele']\n",
    "        length = i['Peptide Length']\n",
    "        fold_change = i['Median Fold Change']\n",
    "        mutation_type = i['Variant Type']\n",
    "        try:\n",
    "            anchor_pos_list = anchor_dict[hla_allele][length]\n",
    "        except:\n",
    "            #anchor_pos_list = [-1]\n",
    "            continue\n",
    "        if if_anchor_matches_mutation_pos(mutation_type, wt_seq, mt_seq, mut_pos, hla_allele, anchor_dict):\n",
    "            at_anchor = 1\n",
    "        else:\n",
    "            at_anchor = 0\n",
    "        condensed_info.append([mut_pos, mutation_type, wt_seq, mt_seq, wt_binding, mt_binding, hla_allele, length, fold_change, at_anchor, anchor_pos_list])\n",
    "    condensed_info_df = pd.DataFrame.from_records(condensed_info, columns=['Mutation Position', 'Variant Type', 'WT Sequence', 'MT Sequence','Median WT Score','Median MT Score', 'HLA Allele', 'Peptide Length', 'Median Fold Change', 'Mutation at Anchor', 'Anchor List'])\n",
    "\n",
    "    anchor_based_decision = []\n",
    "    anchor_based_group = []\n",
    "    og_decision = []\n",
    "    naive_anchor_decision = []\n",
    "    naive_decision_group = []\n",
    "    for n, i in condensed_info_df.iterrows():\n",
    "        anchor_decision, anchor_group = anchor_category_determine(i, cutoff)\n",
    "        naive_anchor, naive_group = naive_anchor_category_determine(i, cutoff)\n",
    "        naive_anchor_decision.append(naive_anchor)\n",
    "        naive_decision_group.append(naive_group)\n",
    "        anchor_based_decision.append(anchor_decision)\n",
    "        anchor_based_group.append(anchor_group)\n",
    "        og_decision.append(original_decision(i))\n",
    "\n",
    "    agreed_decision_1_3 = []\n",
    "    for i,j in zip(og_decision, anchor_based_decision):\n",
    "        if i == j:\n",
    "            agreed_decision_1_3.append('YES')\n",
    "        else:\n",
    "            agreed_decision_1_3.append('NO')\n",
    "\n",
    "    agreed_decision_1_2 = []\n",
    "    for i,j in zip(og_decision, naive_anchor_decision):\n",
    "        if i == j:\n",
    "            agreed_decision_1_2.append('YES')\n",
    "        else:\n",
    "            agreed_decision_1_2.append('NO')\n",
    "\n",
    "    agreed_decision_2_3 = []\n",
    "    for i,j in zip(naive_anchor_decision, anchor_based_decision):\n",
    "        if i == j:\n",
    "            agreed_decision_2_3.append('YES')\n",
    "        else:\n",
    "            agreed_decision_2_3.append('NO')\n",
    "\n",
    "    condensed_info_df['Binding < 100 and FC > 1'] = og_decision\n",
    "    condensed_info_df['Naive Anchor Based decision'] = naive_anchor_decision\n",
    "    condensed_info_df['Naive Anchor Decision Group'] = naive_decision_group\n",
    "    condensed_info_df['Anchor Based decision'] = anchor_based_decision\n",
    "    condensed_info_df['Anchor Decision Group'] = anchor_based_group\n",
    "    condensed_info_df['Do basic & naive decisions agree?'] = agreed_decision_1_2\n",
    "    condensed_info_df['Do naive & calculated decisions agree?'] = agreed_decision_2_3\n",
    "    condensed_info_df['Do basic & calculated decisions agree?'] = agreed_decision_1_3\n",
    "    \n",
    "    print(Counter(og_decision), Counter(naive_anchor_decision), Counter(anchor_based_decision))\n",
    "    filters_decision_combined = pd.DataFrame(columns=['Filter A', 'Filter B', 'Filter C'])\n",
    "    filters_decision_combined['Filter A'] = og_decision\n",
    "    filters_decision_combined['Filter B'] = naive_anchor_decision\n",
    "    filters_decision_combined['Filter C'] = anchor_based_decision\n",
    "    return filters_decision_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_decision_combined_500b = anchor_impact_analysis(tcga_1000_m2_filter_500b, filtered_anchor_dict_r4, 500)\n",
    "filters_decision_combined_100b = anchor_impact_analysis(tcga_1000_m2_filter_100b, filtered_anchor_dict_r4, 100)\n",
    "filters_decision_combined_50b = anchor_impact_analysis(tcga_1000_m2_filter_50b, filtered_anchor_dict_r4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f11ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_table, counts = count_set_occurrences(filters_decision_combined_500b, ['Filter A', 'Filter B', 'Filter C'])\n",
    "\n",
    "for i in zip(upset_table, counts):\n",
    "    print(i)\n",
    "upsetplot.plot(upsetplot.from_memberships(upset_table, data=counts), sort_by='cardinality', show_percentages = True,)\n",
    "#plt.savefig('upset_plot_filters_combined_m2_contribution_80_with_base_500b_filter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c29b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_table, counts = count_set_occurrences(filters_decision_combined_100b, ['Filter A', 'Filter B', 'Filter C'])\n",
    "\n",
    "for i in zip(upset_table, counts):\n",
    "    print(i)\n",
    "upsetplot.plot(upsetplot.from_memberships(upset_table, data=counts), sort_by='cardinality', show_percentages = True,)\n",
    "#plt.savefig('upset_plot_filters_combined_m2_contribution_80_with_base_100b_filter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_table, counts = count_set_occurrences(filters_decision_combined_50b, ['Filter A', 'Filter B', 'Filter C'])\n",
    "\n",
    "for i in zip(upset_table, counts):\n",
    "    print(i)\n",
    "upsetplot.plot(upsetplot.from_memberships(upset_table, data=counts), sort_by='cardinality', show_percentages = True,)\n",
    "#plt.savefig('upset_plot_filters_combined_m2_contribution_80_with_base_50b_filter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e26cd7",
   "metadata": {},
   "source": [
    "## Analysis with filtered HLA alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25077ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out those equal to 2,9 or 9,2\n",
    "all_anchor_overall_pos_score_dict_r4 = load_obj('all_anchor_overall_pos_score_dict_r4')\n",
    "normalized_anchor_dict_r4, filtered_anchor_dict_r4 = anchor_pos_score_by_contribution(all_anchor_overall_pos_score_dict_r4, 0.8)\n",
    "filtered_anchor_dict = {}\n",
    "filtered_out_anchor_dict = {}\n",
    "\n",
    "for i in filtered_anchor_dict_r4:\n",
    "    filtered_anchor_dict[i] = {}\n",
    "    filtered_out_anchor_dict[i] = {}\n",
    "    for length in [8,9,10,11]:\n",
    "        try:\n",
    "            if filtered_anchor_dict_r4[i][length] == [2,length] or filtered_anchor_dict_r4[i][length] == [length, 2]:\n",
    "                filtered_out_anchor_dict[i][length] = filtered_anchor_dict_r4[i][length]\n",
    "            else:\n",
    "                filtered_anchor_dict[i][length] = filtered_anchor_dict_r4[i][length]\n",
    "        except:\n",
    "            #print(filtered_anchor_dict_r4[i])\n",
    "            continue\n",
    "\n",
    "filtered_anchor_dict = {i:filtered_anchor_dict[i] for i in filtered_anchor_dict if filtered_anchor_dict[i] != {}}\n",
    "filtered_out_anchor_dict = {i:filtered_out_anchor_dict[i] for i in filtered_out_anchor_dict if filtered_out_anchor_dict[i] != {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d346612",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out those in clusters other than red, orange, purple\n",
    "hla_list = [\"HLA-A*29:02\",\n",
    "\"HLA-A*30:01\",\n",
    "\"HLA-A*30:02\",\n",
    "\"HLA-A*31:01\",\n",
    "\"HLA-A*33:01\",\n",
    "\"HLA-A*68:01\",\n",
    "\"HLA-A*80:01\",\n",
    "\"HLA-B*08:01\",\n",
    "\"HLA-B*08:09\",\n",
    "\"HLA-B*14:02\",\n",
    "\"HLA-C*04:01\",\n",
    "\"HLA-C*04:03\",\n",
    "\"HLA-C*05:01\",\n",
    "\"HLA-C*05:09\",\n",
    "\"HLA-C*08:02\",\n",
    "\"HLA-C*08:15\"]\n",
    "all_anchor_overall_pos_score_dict_r4 = load_obj('all_anchor_overall_pos_score_dict_r4')\n",
    "normalized_anchor_dict_r4, filtered_anchor_dict_r4 = anchor_pos_score_by_contribution(all_anchor_overall_pos_score_dict_r4, 0.8)\n",
    "filtered_anchor_dict_cluster = {}\n",
    "for i in filtered_anchor_dict_r4:\n",
    "    if i in hla_list:\n",
    "        filtered_anchor_dict_cluster[i] = filtered_anchor_dict_r4[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_anchor_dict), len(filtered_out_anchor_dict), len(filtered_anchor_dict_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_1000_m2_filter_500b_1 = pd.read_csv('filter_500b_TCGA_1000_m1_pvacseq_analysis_combined.txt', sep='\\t')\n",
    "tcga_1000_m2_filter_500b_2 = pd.read_csv('filter_500b_TCGA_1000_m1_pvacseq_re_analysis_combined.txt', sep='\\t')\n",
    "tcga_1000_m2_filter_500b = tcga_1000_m2_filter_500b_1.append(tcga_1000_m2_filter_500b_2)\n",
    "dataset = tcga_1000_m2_filter_500b[tcga_1000_m2_filter_500b[\"Peptide Length\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f626f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_decision_combined_filtered_hla = anchor_impact_analysis(dataset_filtered, filtered_anchor_dict, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_table, counts = count_set_occurrences(filters_decision_combined_filtered_dict, ['Filter A', 'Filter B', 'Filter C'])\n",
    "\n",
    "for i in zip(upset_table, counts):\n",
    "    print(i)\n",
    "ax = upsetplot.plot(upsetplot.from_memberships(upset_table, data=counts), show_percentages = True, sort_by=\"cardinality\")\n",
    "#plt.savefig('upset_plot_filters_combined_m2_contribution_80_no_base_50b_filter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055db1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [\"500 Binding Cutoff\", \"100 Binding Cutoff\", \"50 Binding Cutoff\", \"Filtered for non-conventional anchors\"]\n",
    "metrics = [\"Difference between A & (B | C)\", \"Difference between C & (A | B)\"]\n",
    "percentages = {\n",
    "    \"500\": [38.3, 5.7],\n",
    "    \"100\": [37.4, 5.5],\n",
    "    \"50\": [37.3, 3.6],\n",
    "    \"HLA filter\": [39.2, 7.4]\n",
    "} \n",
    "cutoff_col = []\n",
    "metrics_col = []\n",
    "percentage_col = []\n",
    "for i in percentages:\n",
    "    for j in range(0,2):\n",
    "        cutoff_col.append(i)\n",
    "        metrics_col.append(metrics[j])\n",
    "        percentage_col.append(percentages[i][j])\n",
    "data = pd.DataFrame()\n",
    "data[\"Cutoffs\"] = cutoff_col\n",
    "data[\"Metrics\"] = metrics_col\n",
    "data[\"Percentage\"] = percentage_col\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e60c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = data[data[\"Metrics\"] == \"Difference between A & (B | C)\"], x = \"Metrics\", y = \"Percentage\", hue = \"Cutoffs\")\n",
    "plt.savefig(\"Difference between A & (B | C).pdf\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = data[data[\"Metrics\"] == \"Difference between C & (A | B)\"], x = \"Metrics\", y = \"Percentage\", hue = \"Cutoffs\")\n",
    "plt.savefig(\"Difference between C & (A | B).pdf\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf8aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
