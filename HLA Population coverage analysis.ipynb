{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_hla_data = pd.read_csv('rawAlleleCountsDictionary.tsv', sep='\\t', header=None)\n",
    "global_dict = ast.literal_eval(global_hla_data.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to remove more than two fields\n",
    "reformatted_global_dict = {}\n",
    "for i in global_dict.keys():\n",
    "    reformatted_global_dict[i] = {}\n",
    "    for j in global_dict[i].keys():\n",
    "        sep_j = j.split(\":\")\n",
    "        try:\n",
    "            hla = (':').join(sep_j[:2])\n",
    "        except:\n",
    "            print('Not enough fields: '+j)\n",
    "            continue\n",
    "        if hla not in reformatted_global_dict[i]:\n",
    "            reformatted_global_dict[i][hla] = global_dict[i][j]\n",
    "        else:\n",
    "            reformatted_global_dict[i][hla] += global_dict[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate frequencies by summing and dividing counts\n",
    "sum_counts = {}\n",
    "for i in reformatted_global_dict.keys():\n",
    "    sum_counts[i] = 0\n",
    "    for j in reformatted_global_dict[i].keys():\n",
    "        sum_counts[i] += reformatted_global_dict[i][j]\n",
    "sum_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict_freq = {}\n",
    "for i in reformatted_global_dict.keys():\n",
    "    global_dict_freq[i] = {}\n",
    "    for j in reformatted_global_dict[i].keys():\n",
    "        global_dict_freq[i][j] = reformatted_global_dict[i][j]/sum_counts[i]\n",
    "global_dict_freq_df = pd.DataFrame.from_dict(global_dict_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anchor_overall_pos_score_dict_r4 = load_obj('all_anchor_overall_pos_score_dict_r4')\n",
    "\n",
    "hla_freq_a = global_dict_freq_df.dropna(subset=['A'])['A']\n",
    "hla_freq_b = global_dict_freq_df.dropna(subset=['B'])['B']\n",
    "hla_freq_c = global_dict_freq_df.dropna(subset=['C'])['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_a = []\n",
    "hla_b = []\n",
    "hla_c = []\n",
    "for i in all_anchor_overall_pos_score_dict_r4:\n",
    "    if i.split(\"*\")[0] == 'HLA-A':\n",
    "        hla_a.append(\"HLA-A*\"+i.split(\"*\")[-1])\n",
    "    elif i.split(\"*\")[0] == 'HLA-B':\n",
    "        hla_b.append(\"HLA-B*\"+i.split(\"*\")[-1])\n",
    "    elif i.split(\"*\")[0] == 'HLA-C':\n",
    "        hla_c.append(\"HLA-C*\"+i.split(\"*\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hla_a), len(hla_b), len(hla_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hla_freq_a), len(hla_freq_b), len(hla_freq_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A - Frequency\n",
    "## B - Frequency.1\n",
    "## C - Frequency.4\n",
    "missing_a = []\n",
    "all_percentage_a = 0\n",
    "missing_b = []\n",
    "all_percentage_b = 0\n",
    "missing_c = []\n",
    "all_percentage_c = 0\n",
    "for i in hla_a:\n",
    "    try:\n",
    "        percentage_a = hla_freq_a[i.split('-')[-1]]\n",
    "        all_percentage_a += percentage_a\n",
    "    except:\n",
    "        missing_a.append(i)\n",
    "\n",
    "for i in hla_b:\n",
    "    try:\n",
    "        percentage_b = hla_freq_b[i.split('-')[-1]]\n",
    "        all_percentage_b += percentage_b\n",
    "    except:\n",
    "        missing_b.append(i)\n",
    "\n",
    "for i in hla_c:\n",
    "    try:\n",
    "        percentage_c = hla_freq_c[i.split('-')[-1]]\n",
    "        all_percentage_c += percentage_c\n",
    "    except:\n",
    "        missing_c.append(i)\n",
    "\n",
    "print(all_percentage_a, all_percentage_b, all_percentage_c)\n",
    "print(len(missing_a), len(missing_b), len(missing_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(hla_freq_a['Percentage (%)']), sum(hla_freq_b['Percentage (%)']), sum(hla_freq_c['Percentage (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
